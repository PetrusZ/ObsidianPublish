<!doctype html><html lang=en><head><script async defer data-website-id=de560d7e-374a-4694-943f-f3f01b8dba46 src=https://umami.codeplayer.org:1443/umami.js></script>
<script>function _howxm(){_howxmQueue.push(arguments)}window._howxmQueue=window._howxmQueue||[],_howxm("setAppID","21c1239b-b2d0-45c5-8eab-246d8b16a9d6"),function(){if(t="howxm_script",!document.getElementById(t)){var t,e=document.createElement("script"),n=document.getElementsByTagName("script")[0];e.setAttribute("id",t),e.type="text/javascript",e.async=!0,e.src="https://static.howxm.com/sdk.js",n.parentNode.insertBefore(e,n)}}()</script><script async src="https://www.googletagmanager.com/gtag/js?id=G-PCXDEM5E1Q"></script>
<script>var doNotTrack=!1;if(!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-PCXDEM5E1Q",{anonymize_ip:!1})}</script><meta charset=utf-8><meta name=description content="容器运行时存储 除外挂存储卷外，容器启动后，运行时所需文件系统性能直接影响容器性能；
早期的 Docker 采用 Device Mapper 作为容器运行时存储驱动，因为 OverlayFS尚未合并进Kernel；
目前 Docker 和 containerd都默认以OverlayFS 作为运行时存储驱动；
OverlayFS目前已经有非常好的性能，与DeviceMapper 相比优 20%，与操作主机文件性能几乎一致
存储卷插件管理 Kubernetes支持以插件的形式来实现对不同存储的支持和扩展，这些扩展基于如下三种方式：
 out-of-tree CSI插件 CSI 通过 RPC与存储驱动进行交互。"><meta property="og:title" content="CSI"><meta property="og:description" content="容器运行时存储 除外挂存储卷外，容器启动后，运行时所需文件系统性能直接影响容器性能；
早期的 Docker 采用 Device Mapper 作为容器运行时存储驱动，因为 OverlayFS尚未合并进Kernel；
目前 Docker 和 containerd都默认以OverlayFS 作为运行时存储驱动；
OverlayFS目前已经有非常好的性能，与DeviceMapper 相比优 20%，与操作主机文件性能几乎一致
存储卷插件管理 Kubernetes支持以插件的形式来实现对不同存储的支持和扩展，这些扩展基于如下三种方式：
 out-of-tree CSI插件 CSI 通过 RPC与存储驱动进行交互。"><meta property="og:type" content="website"><meta property="og:image" content="https://obsidian.codeplayer.org/icon.png"><meta property="og:url" content="https://obsidian.codeplayer.org/CS/Kubernetes/CSI/"><meta property="og:width" content="200"><meta property="og:height" content="200"><meta name=twitter:card content="summary"><meta name=twitter:title content="CSI"><meta name=twitter:description content="容器运行时存储 除外挂存储卷外，容器启动后，运行时所需文件系统性能直接影响容器性能；
早期的 Docker 采用 Device Mapper 作为容器运行时存储驱动，因为 OverlayFS尚未合并进Kernel；
目前 Docker 和 containerd都默认以OverlayFS 作为运行时存储驱动；
OverlayFS目前已经有非常好的性能，与DeviceMapper 相比优 20%，与操作主机文件性能几乎一致
存储卷插件管理 Kubernetes支持以插件的形式来实现对不同存储的支持和扩展，这些扩展基于如下三种方式：
 out-of-tree CSI插件 CSI 通过 RPC与存储驱动进行交互。"><meta name=twitter:image content="https://obsidian.codeplayer.org/icon.png"><title>CSI</title><meta name=viewport content="width=device-width,initial-scale=1"><link rel="shortcut icon" type=image/png href=https://obsidian.codeplayer.org//icon.png><link href=https://obsidian.codeplayer.org/styles.80333fa2099c0bee674efa435fde378c.min.css rel=stylesheet><link href=https://obsidian.codeplayer.org/styles/_light_syntax.86a48a52faebeaaf42158b72922b1c90.min.css rel=stylesheet id=theme-link><script src=https://obsidian.codeplayer.org/js/darkmode.245a0a31da505f6b327aec1fcae860c8.min.js></script>
<script src=https://obsidian.codeplayer.org/js/util.00639692264b21bc3ee219733d38a8be.min.js></script>
<link rel=preload href=https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.css as=style onload='this.onload=null,this.rel="stylesheet"' integrity=sha384-R4558gYOUz8mP9YWpZJjofhk+zx0AS11p36HnD2ZKj/6JR5z27gSSULCNHIRReVs crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.js integrity=sha384-z1fJDqw8ZApjGO3/unPWUPsIymfsJmyrDVWC8Tv/a1HeOtGmkwNd/7xUS0Xcnvsx crossorigin=anonymous></script>
<script defer src=https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/contrib/auto-render.min.js integrity=sha384-+XBljXPPiv+OzfbB3cVmLHf4hdUFHlWNZN5spNQ7rmHTXpd7WvJum6fIACpNNfIR crossorigin=anonymous></script>
<script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.2/dist/contrib/copy-tex.min.js integrity=sha384-ww/583aHhxWkz5DEVn6OKtNiIaLi2iBRNZXfJRiY1Ai7tnJ9UXpEsyvOITVpTl4A crossorigin=anonymous></script>
<script src=https://cdn.jsdelivr.net/npm/@floating-ui/core@1.2.1></script>
<script src=https://cdn.jsdelivr.net/npm/@floating-ui/dom@1.2.1></script>
<script async src=https://obsidian.codeplayer.org/js/popover.aa9bc99c7c38d3ae9538f218f1416adb.min.js></script>
<script defer src=https://obsidian.codeplayer.org/js/code-title.ce4a43f09239a9efb48fee342e8ef2df.min.js></script>
<script defer src=https://obsidian.codeplayer.org/js/clipboard.2913da76d3cb21c5deaa4bae7da38c9f.min.js></script>
<script defer src=https://obsidian.codeplayer.org/js/callouts.7723cac461d613d118ee8bb8216b9838.min.js></script>
<script>const SEARCH_ENABLED=!1,LATEX_ENABLED=!0,PRODUCTION=!0,BASE_URL="https://obsidian.codeplayer.org/",fetchData=Promise.all([fetch("https://obsidian.codeplayer.org/indices/linkIndex.c4c4c4c7a7ef56e411497c00ff176ea1.min.json").then(e=>e.json()).then(e=>({index:e.index,links:e.links})),fetch("https://obsidian.codeplayer.org/indices/contentIndex.868a085a6226bf4142875743a938cc52.min.json").then(e=>e.json())]).then(([{index:e,links:t},n])=>({index:e,links:t,content:n})),render=()=>{const e=new URL(BASE_URL),t=e.pathname,n=window.location.pathname,s=t==n;addCopyButtons(),addTitleToCodeBlocks(),addCollapsibleCallouts(),initPopover("https://obsidian.codeplayer.org",!0);const o=document.getElementById("footer");if(o){const e=document.getElementById("graph-container");if(!e)return requestAnimationFrame(render);e.textContent="";const t=s&&!1;drawGraph("https://obsidian.codeplayer.org",t,[{"/moc":"#4388cc"}],t?{centerForce:1,depth:-1,enableDrag:!0,enableLegend:!1,enableZoom:!0,fontSize:.5,linkDistance:1,opacityScale:3,repelForce:1,scale:1.4}:{centerForce:1,depth:1,enableDrag:!0,enableLegend:!1,enableZoom:!0,fontSize:.6,linkDistance:1,opacityScale:3,repelForce:2,scale:1.2})}var i=document.getElementsByClassName("mermaid");i.length>0&&import("https://unpkg.com/mermaid@9/dist/mermaid.esm.min.mjs").then(e=>{e.default.init()});function a(n){const e=n.target,t=e.className.split(" "),s=t.includes("broken"),o=t.includes("internal-link");plausible("Link Click",{props:{href:e.href,broken:s,internal:o,graph:!1}})}const r=document.querySelectorAll("a");for(link of r)link.className.includes("root-title")&&link.addEventListener("click",a,{once:!0})},init=(e=document)=>{addCopyButtons(),addTitleToCodeBlocks(),renderMathInElement(e.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1}],macros:{'’':"'"},throwOnError:!1})}</script><script type=module>
    import { attachSPARouting } from "https:\/\/obsidian.codeplayer.org\/js\/router.d6fe6bd821db9ea97f9aeefae814d8e7.min.js"
    attachSPARouting(init, render)
  </script><script defer data-domain=obsidian.codeplayer.org src=https://plausible.io/js/script.js></script>
<script>window.plausible=window.plausible||function(){(window.plausible.q=window.plausible.q||[]).push(arguments)}</script></head><body><div id=search-container><div id=search-space><input autocomplete=off id=search-bar name=search type=text aria-label=Search placeholder="Search for something..."><div id=results-container></div></div></div><script src=https://cdn.jsdelivr.net/npm/flexsearch@0.7.21/dist/flexsearch.bundle.js integrity="sha256-i3A0NZGkhsKjVMzFxv3ksk0DZh3aXqu0l49Bbh0MdjE=" crossorigin=anonymous defer></script>
<script defer src=https://obsidian.codeplayer.org/js/full-text-search.e6e2e0c213187ca0c703d6e2c7a77fcd.min.js></script><div class=singlePage><header><h1 id=page-title><a class=root-title href=https://obsidian.codeplayer.org/>Avalon Obsidian Vault</a></h1><div class=spacer></div><div id=search-icon><p>Search</p><svg tabindex="0" aria-labelledby="title desc" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 19.9 19.7"><title id="title">Search Icon</title><desc id="desc">Icon to open search</desc><g class="search-path" fill="none"><path stroke-linecap="square" d="M18.5 18.3l-5.4-5.4"/><circle cx="8" cy="8" r="7"/></g></svg></div><div class=darkmode><input class=toggle id=darkmode-toggle type=checkbox tabindex=-1>
<label id=toggle-label-light for=darkmode-toggle tabindex=-1><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" id="dayIcon" viewBox="0 0 35 35" style="enable-background:new 0 0 35 35"><title>Light Mode</title><path d="M6 17.5C6 16.672 5.328 16 4.5 16h-3C.672 16 0 16.672.0 17.5S.672 19 1.5 19h3C5.328 19 6 18.328 6 17.5zM7.5 26c-.414.0-.789.168-1.061.439l-2 2C4.168 28.711 4 29.086 4 29.5 4 30.328 4.671 31 5.5 31c.414.0.789-.168 1.06-.44l2-2C8.832 28.289 9 27.914 9 27.5 9 26.672 8.329 26 7.5 26zm10-20C18.329 6 19 5.328 19 4.5v-3C19 .672 18.329.0 17.5.0S16 .672 16 1.5v3C16 5.328 16.671 6 17.5 6zm10 3c.414.0.789-.168 1.06-.439l2-2C30.832 6.289 31 5.914 31 5.5 31 4.672 30.329 4 29.5 4c-.414.0-.789.168-1.061.44l-2 2C26.168 6.711 26 7.086 26 7.5 26 8.328 26.671 9 27.5 9zM6.439 8.561C6.711 8.832 7.086 9 7.5 9 8.328 9 9 8.328 9 7.5c0-.414-.168-.789-.439-1.061l-2-2C6.289 4.168 5.914 4 5.5 4 4.672 4 4 4.672 4 5.5c0 .414.168.789.439 1.06l2 2.001zM33.5 16h-3c-.828.0-1.5.672-1.5 1.5s.672 1.5 1.5 1.5h3c.828.0 1.5-.672 1.5-1.5S34.328 16 33.5 16zM28.561 26.439C28.289 26.168 27.914 26 27.5 26c-.828.0-1.5.672-1.5 1.5.0.414.168.789.439 1.06l2 2C28.711 30.832 29.086 31 29.5 31c.828.0 1.5-.672 1.5-1.5.0-.414-.168-.789-.439-1.061l-2-2zM17.5 29c-.829.0-1.5.672-1.5 1.5v3c0 .828.671 1.5 1.5 1.5s1.5-.672 1.5-1.5v-3C19 29.672 18.329 29 17.5 29zm0-22C11.71 7 7 11.71 7 17.5S11.71 28 17.5 28 28 23.29 28 17.5 23.29 7 17.5 7zm0 18c-4.136.0-7.5-3.364-7.5-7.5s3.364-7.5 7.5-7.5 7.5 3.364 7.5 7.5S21.636 25 17.5 25z"/></svg></label><label id=toggle-label-dark for=darkmode-toggle tabindex=-1><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" id="nightIcon" viewBox="0 0 100 100" style="enable-background='new 0 0 100 100'"><title>Dark Mode</title><path d="M96.76 66.458c-.853-.852-2.15-1.064-3.23-.534-6.063 2.991-12.858 4.571-19.655 4.571C62.022 70.495 50.88 65.88 42.5 57.5 29.043 44.043 25.658 23.536 34.076 6.47c.532-1.08.318-2.379-.534-3.23-.851-.852-2.15-1.064-3.23-.534-4.918 2.427-9.375 5.619-13.246 9.491-9.447 9.447-14.65 22.008-14.65 35.369.0 13.36 5.203 25.921 14.65 35.368s22.008 14.65 35.368 14.65c13.361.0 25.921-5.203 35.369-14.65 3.872-3.871 7.064-8.328 9.491-13.246C97.826 68.608 97.611 67.309 96.76 66.458z"/></svg></label></div></header><article><h1>CSI</h1><p class=meta>Last updated
Apr 9, 2023
<a href=https://github.com/PetrusZ/avalon-obsidian-vault/tree/main/CS/Kubernetes/CSI.md rel=noopener>Edit Source</a></p><ul class=tags><li><a href=https://obsidian.codeplayer.org/tags/CS/Kubernetes/>Cs kubernetes</a></li></ul><aside class=mainTOC><details open><summary>Table of Contents</summary><nav id=TableOfContents><ol><li><a href=#容器运行时存储>容器运行时存储</a></li><li><a href=#存储卷插件管理>存储卷插件管理</a></li><li><a href=#out-of-tree-csi插件>out-of-tree CSI插件</a></li><li><a href=#csi驱动>CSI驱动</a></li><li><a href=#临时存储>临时存储</a></li><li><a href=#半持久化存储>半持久化存储</a></li><li><a href=#hostpath-卷需要注意>hostPath 卷需要注意</a></li><li><a href=#持久化存储>持久化存储</a><ol><li><a href=#storageclass>StorageClass</a></li><li><a href=#pvc>PVC</a></li><li><a href=#pv>PV</a></li><li><a href=#存储对象关系>存储对象关系</a></li></ol></li><li><a href=#生产实践经验分享>生产实践经验分享</a></li><li><a href=#独占的-local-volume>独占的 Local Volume</a></li><li><a href=#dynamic-local-volume>Dynamic Local Volume</a></li><li><a href=#local-dynamic-的挂载流程>Local Dynamic 的挂载流程</a></li><li><a href=#local-dynamic-的挑战>Local Dynamic 的挑战</a></li><li><a href=#生产实践经验分享-1>生产实践经验分享</a></li></ol></nav></details></aside><a href=#容器运行时存储><h1 id=容器运行时存储><span class=hanchor arialabel=Anchor># </span>容器运行时存储</h1></a><p>除外挂存储卷外，容器启动后，运行时所需文件系统性能直接影响容器性能；</p><p>早期的 Docker 采用 Device Mapper 作为容器运行时存储驱动，因为 OverlayFS尚未合并进Kernel；</p><p>目前 Docker 和 containerd都默认以OverlayFS 作为运行时存储驱动；</p><p>OverlayFS目前已经有非常好的性能，与DeviceMapper 相比优 20%，与操作主机文件性能几乎一致</p><a href=#存储卷插件管理><h1 id=存储卷插件管理><span class=hanchor arialabel=Anchor># </span>存储卷插件管理</h1></a><p>Kubernetes支持以插件的形式来实现对不同存储的支持和扩展，这些扩展基于如下三种方式：</p><p><img src=https://obsidian.codeplayer.org//Assets/image_1666114625255_0.png width=auto alt=image.png></p><a href=#out-of-tree-csi插件><h1 id=out-of-tree-csi插件><span class=hanchor arialabel=Anchor># </span>out-of-tree CSI插件</h1></a><p>CSI 通过 RPC与存储驱动进行交互。</p><p>在设计 CSI的时候，Kubernetes 对CSI存储驱动的打包和部署要求很少，主要定义了Kubernetes 的两个相关模块：</p><ul><li><strong>kube-controller-manager：</strong><ul><li>kube-controller-manager 模块用于感知CSI驱动存在。</li><li>Kubernetes 的主控模块通过Unix domain socket（而不是CSI驱动）或者其他方式进行直接地交互。</li><li>Kubernetes 的主控模块只与 Kubernetes相关的 API进行交互。</li><li>因此CSI驱动若有依赖于Kubernetes API 的操作，例如卷的创建、卷的 attach、卷的快照等，需要在 CSI驱动里面通过Kubernetes 的 API，来触发相关的CSI操作。</li></ul></li><li><strong>kubelet：</strong><ul><li>kubelet模块用于与 CSI驱动进行交互。</li><li>kubelet通过 Unix domain socket 向 CSI驱动发起 CSI 调用（如 NodeStageVolume、NodePublishVolume 等），再发起 mount 卷和 umount卷。</li><li>kubelet通过插件注册机制发现 CSI驱动及用于和 CSI驱动交互的 Unix Domain Socket。</li><li>所有部署在 Kubernetes集群中的 CSI驱动都要通过kubelet 的插件注册机制来注册自己。</li></ul></li></ul><a href=#csi驱动><h1 id=csi驱动><span class=hanchor arialabel=Anchor># </span>CSI驱动</h1></a><p>CSI 的驱动一般包含external-attacher、external-provisioner、external-resizer、externalsnapshotter、node-driver-register、CSI driver 等模块，可以根据实际的存储类型和需求进行不同方式的部署。</p><p><img src=https://obsidian.codeplayer.org//Assets/image_1666115068189_0.png width=auto alt=image.png></p><a href=#临时存储><h1 id=临时存储><span class=hanchor arialabel=Anchor># </span>临时存储</h1></a><p>常见的临时存储主要就是emptyDir 卷。</p><p>emptyDir 是一种经常被用户使用的卷类型，顾名思义，&ldquo;卷"最初是空的。当 Pod 从节点上删除时，emptyDir 卷中的数据也会被永久删除。但当 Pod 的容器因为某些原因退出再重启时，emptvDir 卷内的数据并不会丢失。</p><p>默认情况下，emptvDir 卷存储在支持该节点所使用的存储介质上，可以是本地磁盘或网络存储。emptyDir 也可以通过将 emptyDir.medium 字段设置为"Memory"来通知Kubernetes为容器安装tmpfs，此时数据被存储在内存中，速度相对于本地存储和网络存储快很多。但是在节点重启的时候，内存数据会被清除;而如果存在磁盘上，则重启后数据依然存在。另外，使用 tmpfs 的内存也会计入容器的使用内存总量中，受系统的Cgroup 限制。</p><p>emptyDir 设计的初衷主要是给应用充当缓存空间，或者存储中间数据，用于快速恢复。然而，这并不是说满足以上需求的用户都被推荐使用 emptyDir，我们要根据用户业务的实际特点来判断是否使用emptyDir。因为 emptyDir 的空间位于系统根盘，被所有容器共享，所以在磁盘的使用率较高时会触发Pod 的 eviction 操作，从而影响业务的稳定。</p><a href=#半持久化存储><h1 id=半持久化存储><span class=hanchor arialabel=Anchor># </span>半持久化存储</h1></a><p>常见的半持久化存储主要是hostPath卷。hostPath卷能将主机节点文件系统上的文件或目录挂载到指定 Pod 中。对普通用户而言一般不需要这样的卷，但是对很多需要获取节点系统信息的Pod而言，却是非常必要的。</p><p>例如，hostPath 的用法举例如下：</p><ul><li>某个Pod 需要获取节点上所有Pod 的 log，可以通过hostPath 访问所有 Pod 的 stdout输出存储目录，例如/Var/log/pods 路径。</li><li>某个Pod 需要统计系统相关的信息，可以通过 hostPath 访问系统的/proc目录。</li></ul><p>使用 hostPath 的时候，除设置必需的path 属性外，用户还可以有选择性地为 hostPath 卷指定类型，支持类型包含目录、字符设备、块设备等。</p><a href=#hostpath-卷需要注意><h1 id=hostpath-卷需要注意><span class=hanchor arialabel=Anchor># </span>hostPath 卷需要注意</h1></a><p>使用同一个目录的 Pod 可能会由于调度到不同的节点，导致目录中的内容有所不同。</p><p>Kubernetes在调度时无法顾及由 hostPath 使用的资源。</p><p>Pod被删除后，如果没有特别处理，那么hostPath上写的数据会遗留到节点上，占用磁盘空间。</p><a href=#持久化存储><h1 id=持久化存储><span class=hanchor arialabel=Anchor># </span>持久化存储</h1></a><p>支持持久化的存储是所有分布式系统所必备的特性。针对持久化存储，Kubernetes 引入了StorageClass、Volume、PVC（Persistent Volume Claim）、PV（Persitent Volume）的概念，将存储独立于 Pod 的生命周期来进行管理。</p><p>Kuberntes 目前支持的持久化存储包含各种主流的块存储和文件存储，譬如 awsElasticBlockStore、azureDisk、cinder、NFS、cephfs、iscsi 等，在大类上可以将其分为网络存储和本地存储两种类型</p><a href=#storageclass><h2 id=storageclass><span class=hanchor arialabel=Anchor># </span>StorageClass</h2></a><p>StorageClass用于指示存储的类型，不同的存储类型可以通过不同的 StorageClass 来为用户提供服务。StorageClass 主要包含存储插件 provisioner、卷的创建和 mount 参数等字段。</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-yaml data-lang=yaml><span class=line><span class=cl><span class=nt>allowVolumeExpansion</span><span class=p>:</span><span class=w> </span><span class=kc>true</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>apiVersion</span><span class=p>:</span><span class=w> </span><span class=l>storage.k8s.io/v1</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>kind</span><span class=p>:</span><span class=w> </span><span class=l>StorageClass</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>metadata</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>annotations</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>storageclass.kubernetes.io/is-default-class</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;false&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>rook-ceph-block</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>parameters</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>clusterID</span><span class=p>:</span><span class=w> </span><span class=l>rook-ceph</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>csi.storage.k8s.io/controller-expand-secret-name</span><span class=p>:</span><span class=w> </span><span class=l>rook-csi-rbd-provisioner</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>csi.storage.k8s.io/controller-expand-secret-namespace</span><span class=p>:</span><span class=w> </span><span class=l>rook-ceph</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>Csi.storage.k8s.io/fstype</span><span class=p>:</span><span class=w> </span><span class=l>ext4</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>csi.storage.k8s.io/node-stage-secret-name</span><span class=p>:</span><span class=w> </span><span class=l>rook-Csi-rbd-node</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>Csi.storage.k8s.io/node-stage-secret-namespace</span><span class=p>:</span><span class=w> </span><span class=l>rook-Ceph</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>csi.storage.k8s.io/provisioner-secret-name</span><span class=p>:</span><span class=w> </span><span class=l>rook-csi-rbd-provisioner</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>csi.storage.k8s.io/provisioner-secret-namespace</span><span class=p>:</span><span class=w> </span><span class=l>rook-ceph</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>imageFeatures</span><span class=p>:</span><span class=w> </span><span class=l>layering</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>imageFormat</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;2&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>pool</span><span class=p>:</span><span class=w> </span><span class=l>replicapool</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>provisioner</span><span class=p>:</span><span class=w> </span><span class=l>rook-ceph.rbd.csi.ceph.com</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>reclaimPolicy</span><span class=p>:</span><span class=w> </span><span class=l>Delete</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>volumeBindingMode</span><span class=p>:</span><span class=w> </span><span class=l>Immediate</span><span class=w>
</span></span></span></code></pre></td></tr></table></div></div><a href=#pvc><h2 id=pvc><span class=hanchor arialabel=Anchor># </span>PVC</h2></a><p>由用户创建，代表用户对存储需求的声明，主要包含需要的存储大小、存储卷的访问模式、StroageClass 等类型，其中存储卷的访问模式必须与存储的类型一致</p><p><img src=https://obsidian.codeplayer.org//Assets/image_1666116424400_0.png width=auto alt=image.png></p><a href=#pv><h2 id=pv><span class=hanchor arialabel=Anchor># </span>PV</h2></a><p>由集群管理员提前创建，或者根据 PVC的申请需求动态地创建，它代表系统后端的真实的存储空间，可以称之为卷空间。</p><a href=#存储对象关系><h2 id=存储对象关系><span class=hanchor arialabel=Anchor># </span>存储对象关系</h2></a><p>用户通过创建 PVC来申请存储。控制器通过 PVC的 StorageClass 和请求的大小声明来存储后端创建卷，进而创建 PV，Pod 通过指定 PVC来引用存储。</p><p><img src=https://obsidian.codeplayer.org//Assets/image_1666116488809_0.png width=auto alt=image.png></p><a href=#生产实践经验分享><h1 id=生产实践经验分享><span class=hanchor arialabel=Anchor># </span>生产实践经验分享</h1></a><p>不同介质类型的磁盘，需要设置不同的 StorageClass，以便让用户做区分。StorageClass需要设置磁盘介质的类型，以便用户了解该类存储的属性。</p><p>在本地存储的 PV静态部署模式下，每个物理磁盘都尽量只创建一个 PV，而不是划分为多个分区来提供多个本地存储 PV，避免在使用时分区之间的I/O干扰。</p><p>本地存储需要配合磁盘检测来使用。当集群部署规模化后，每个集群的本地存储 PV 可能会超过几万个，如磁盘损坏将是频发事件。此时，需要在检测到磁盘损坏、丢盘等问题后，对节点的磁盘和相应的本地存储 PV进行特定的处理，例如触发告警、自动 cordon 节点、自动通知用户等。</p><p>对干提供本地存储节点的磁盘管理，需要做到灵活管理和自动化。节点磁盘的信息可以归一、集中化管理。在local-Volume-provisioner 中增加部署逻辑，当容器运行起来时，拉取该节点需要提供本地存储的磁盘信息，例如磁盘的设备路径，以Filesystem 或 Block 的模式提供本地存储，或者是否需要加入某个LVM的虚拟组（VG）等。local-volume-provisioner 根据获取的磁盘信息对磁盘进行格式化，或者加入到某个VG，从而形成对本地存储支持的自动化闭环。</p><a href=#独占的-local-volume><h1 id=独占的-local-volume><span class=hanchor arialabel=Anchor># </span>独占的 Local Volume</h1></a><p>创建 PV：通过local-volume-provisioner DaemonSet创建本地存储的PV。
创建PVC：用户创建PVC，由于它处于pending状态，所以kube-controller-manager并不会对该PVC做任何操作。</p><p>创建Pod：用户创建Pod。</p><p>Pod挑选节点：kube-scheduler开始调度Pod，通过PVC的resources.request.storage和volumeMode选择满足条件的PV，并且为Pod选择一个合适的节点。</p><p>更新PV：kube-scheduler将PV的pv.Spec.claimRef设置为对应的PVC，并且设置 <code>annotation pv.kubernetes.io/bound-by-controller</code> 的值为“yes”。</p><p>PVC和PV绑定：pv_controller同步PVC和PV的状态，并将PVC和PV进行绑定。</p><p>监听PVC对象：kube-scheduler等待PVC的状态变成 Bound状态。</p><p>Pod 调度到节点：如果PVC的状态变为Bound则说明调度成功，而如果PVC一直处于pending状态，超时后会再次进行调度。</p><p>Mount 卷启动容器：kubelet 监听到有Pod 已经调度到节点上，对本地存储进行mount操作，并启动容器。</p><p><img src=https://obsidian.codeplayer.org//Assets/image_1666116919277_0.png width=auto alt=image.png></p><a href=#dynamic-local-volume><h1 id=dynamic-local-volume><span class=hanchor arialabel=Anchor># </span>Dynamic Local Volume</h1></a><p>CSI驱动需要汇报节点上相关存储的资源信息，以便用于调度但是机器的厂家不同，汇报方式也不同。</p><p>例如，有的厂家的机器节点上具有 NVMe、SSD、HDD等多种存储介质，希望将这些存储介质分别进行汇报。</p><p>这种需求有别于其他存储类型的 CSI驱动对接口的需求，因此如何汇报节点的存储信息，以及如何让节点的存储信息应用于调度，目前并没有形成统一的意见。</p><p>集群管理员可以基于节点存储的实际情况对开源CSI 驱动和调度进行一些代码修改，再进行部署和使用</p><a href=#local-dynamic-的挂载流程><h1 id=local-dynamic-的挂载流程><span class=hanchor arialabel=Anchor># </span>Local Dynamic 的挂载流程</h1></a><p>创建PVC：用户创建PVC，PVC处于pending状态。</p><p>创建Pod：用户创建Pod。</p><p>Pod 选择节点：kube-scheduler开始调度Pod，通过PVC的pvc.spec.resources.request.storage等选择满足条件的节点。</p><p>更新PVC：选择节点后，kube-scheduler会给PVC添加包含节点信息的 <code>annotation∶ volume.kubernetes.io/selected-node∶&lt;节点名字></code>。</p><p>创建卷：运行在节点上的容器 external-provisioner 监听到PVC带有该节点相关的annotation，向相应的CSI驱动申请分配卷。</p><p>创建PV：PVC申请到所需的存储空间后，external-provisioner创建PV，该PV的pv.Spec.claimRef设置为对应的PVC。</p><p>PVC和PV绑定：kube-controller-manager将PVC和PV进行绑定，状态修改为 Bound。</p><p>监听PVC状态：kube-scheduler等待PVC变成Bound状态。</p><p>Pod调度到节点：当PVC的状态为Bound时，Pod才算真正调度成功了。如果PVC一直处于Pending状态，超时后会再次进行调度。</p><p>Mount卷：kubelet监听到有Pod已经调度到节点上，对本地存储进行mount操作。</p><p>启动容器：启动容器。</p><p><img src=https://obsidian.codeplayer.org//Assets/image_1666117282847_0.png width=auto alt=image.png></p><a href=#local-dynamic-的挑战><h1 id=local-dynamic-的挑战><span class=hanchor arialabel=Anchor># </span>Local Dynamic 的挑战</h1></a><p>如果将磁盘空间作为一个存储池（例如LVM）来动态分配，那么在分配出来的逻辑卷空间的使用上，可能会受到其他逻辑卷的I/O干扰，因为底层的物理卷可能是同一个。</p><p>如果 PV后端的磁盘空间是一块独立的物理磁盘，则I/O 就不会受到干扰。</p><a href=#生产实践经验分享-1><h1 id=生产实践经验分享-1><span class=hanchor arialabel=Anchor># </span>生产实践经验分享</h1></a><p>不同介质类型的磁盘，需要设置不同的 StorageClass，以便让用户做区分。StorageClass需要设置磁盘介质的类型，以便用户了解该类存储的属性。</p><p>在本地存储的 PV 静态部署模式下，每个物理磁盘都尽量只创建一个PV，而不是划分为多个分区来提供多个本地存储 PV，避免在使用时分区之间的I/O 干扰。</p><p>本地存储需要配合磁盘检测来使用。当集群部署规模化后，每个集群的本地存储 PV 可能会超过几万个，如磁盘损坏将是频发事件。此时，需要在检测到磁盘损坏、丢盘等问题后，对节点的磁盘和相应的本地存储 PV进行特定的处理，例如触发告警、自动 cordon 节点、自动通知用户等。</p><p>对于提供本地存储节点的磁盘管理，需要做到灵活管理和自动化。节点磁盘的信息可以归一、集中化管理。在 loCal-Volume-proVisioner 中增加部署逻辑，当容器运行起来时，拉取该节点需要提供本地存储的磁盘信息，例如磁盘的设备路径，以Filesystem 或 Block 的模式提供本地存储，或者是否需要加入某个LVM的虚拟组（VG）等。local-volume-provisioner根据获取的磁盘信息对磁盘进行格式化，或者加入到某个VG，从而形成对本地存储支持的自动化闭环。</p></article><hr><div class=page-end id=footer><div class=backlinks-container><h3>Backlinks</h3><ul class=backlinks><li>No backlinks found</li></ul></div><div><script async src=https://cdn.jsdelivr.net/npm/d3@6.7.0/dist/d3.min.js integrity="sha256-+7jaYCp29O1JusNWHaYtgUn6EhuP0VaFuswhNV06MyI=" crossorigin=anonymous></script><h3>Interactive Graph</h3><div id=graph-container></div><style>:root{--g-node:var(--secondary);--g-node-active:var(--primary);--g-node-inactive:var(--visited);--g-link:var(--outlinegray);--g-link-active:#5a7282}</style><script src=https://obsidian.codeplayer.org/js/graph.6579af7b10c818dbd2ca038702db0224.js></script></div></div><div id=contact_buttons><footer><p>Made by Patrick Zhao using <a href=https://github.com/jackyzha0/quartz>Quartz</a>, © 2023</p><ul><li><a href=https://obsidian.codeplayer.org/>Home</a></li><li><a href=https://github.com/PetrusZ>GitHub</a></li><li><a href=https://t.me/Petrus_Z>Telegram</a></li><li><a href=mailto:silencly07@gmail.com>Email</a></li></ul></footer></div><hr><script src=https://giscus.app/client.js data-repo=PetrusZ/ObsidianPublish data-repo-id=R_kgDOJTGL0A data-category=Announcements data-category-id=DIC_kwDOJTGL0M4CVohQ data-mapping=title data-strict=0 data-reactions-enabled=1 data-emit-metadata=0 data-input-position=top data-theme=preferred_color_scheme data-lang=zh-CN crossorigin=anonymous async></script></div></body></html>